import streamlit as st
from langchain import OpenAI
from langchain import PromptTemplate
from langchain.docstore.document import Document
from langchain.chains.question_answering import load_qa_chain
from langchain.text_splitter import CharacterTextSplitter, RecursiveCharacterTextSplitter
from langchain.chains.summarize import load_summarize_chain
# import openai


text ="ë„ˆëŠ” ê³ ê°ì„¼í„°ì´ë‹¤. ì‹œìŠ¤í…œ ì—”ì§€ë‹ˆì–´ê²Œ ë¬¸ì œë‚˜ ì§ˆë¬¸ì„ í•´ê²°í• ìˆ˜ ìˆë„ë¡ ì•„ë˜ í˜•ì‹ìœ¼ë¡œ ì •ë³´ë¥¼ ì œê³µí•¨.\
ê²½ìš°ë³„ êµ¬ë¶„í•˜ì—¬ í‘œì‹œ, ì¸í”„ë¼(Network, Database, Interface, ìœ ê´€ê¸°ê´€) ì—ëŸ¬ë¥¼ ìš°ì„ , \
ì¥ì• ë“±ê¸‰ì´ 1,2,3,4 ì¤‘ ì‘ì€ìˆ«ìë¥¼ ìš°ì„ í•˜ì—¬ ì¡°íšŒ ,\
ê°€ëŠ¥í•˜ë©´, í‘œë¥¼ ì‚¬ìš©í•˜ì—¬ í‘œì‹œí•˜ê³ , \
ê´€ë ¨ ìˆëŠ” 3ê°œ ì´ìƒì˜ ê±´ì„ í‘œì‹œí•˜ê³  \
í‘œì‹œí•  ì •ë³´ì˜ ìƒì„¸ í•­ëª©ì€ ì•„ë˜ì™€ ê°™ê³  page ë³„ë¡œ í‘œì‹œ í•´ì¤˜  \
.ì¥ì• ë²ˆí˜¸:  \
.ì¥ì• ë‚´ìš©:  \
.ì¥ì• ìœ í˜•:\
.ë‹´ë‹¹ì: \
.ë°œìƒì¼ì‹œ: \
.ì˜í–¥ë„: \
.ê³ ê°ì‚¬: \
 "

def generate_response(txt,text):
    # Instantiate the LLM model
    llm = OpenAI(temperature=0, openai_api_key=openai_api_key)
    # Split text
    # text_splitter = CharacterTextSplitter()
    text_splitter = CharacterTextSplitter(chunk_size=2048, chunk_overlap=0)
    # text_splitter = RecursiveCharacterTextSplitter(chunk_size=2048, chunk_overlap=0) 
    texts = text_splitter.split_text(txt)
    # Create multiple documents
    docs = [Document(page_content=t) for t in texts]


    print(f"len(docs) : {len(docs)}")
    print(f"docs : {docs}")
    # Text summarization

    prompt_template = """

    {text}

    """
    PROMPT = PromptTemplate(template=prompt_template, input_variables=["text"])

    # chain =load_summarize_chain(llm, chain_type="stuff", prompt=PROMPT) 
    # chain = load_summarize_chain(llm, chain_type="refine",verbose=True,refine_prompt=PROMPT)
    # chain = load_summarize_chain(llm, chain_type="map_reduce",map_prompt=PROMPT, combine_prompt=PROMPT)
    # chain = load_summarize_chain(llm, chain_type='map_reduce')
    #  return chain.run(docs)
    _question = f"{text}{'ì¸ì¦ ì§€ì—° ì¥ì• ëŠ” ìˆì—ˆë‚˜ìš”?'}"
    #chain = load_qa_chain(llm = llm , chain_type="stuff")
    chain = load_qa_chain(llm=llm, chain_type="stuff")
    print(f"LLM Question :{_question}")
    response = chain({"input_documents": docs, "question": _question }, return_only_outputs=True)

    return response

# Page title
st.set_page_config(page_title='ğŸ¦œğŸ”— Text Summarization App')
st.title('ğŸ¦œğŸ”— Text Summarization App')

# Text input
txt_input = st.text_area('Enter your text', '', height=200)
openai_api_org=""
openai_api_key="sk-"

# # Form to accept user's text input for summarization
result = []
with st.form('summarize_form', clear_on_submit=True):
    # openai_api_key = st.text_input('OpenAI API Key', type = 'password', disabled=not txt_input)
    submitted = st.form_submit_button('Submit')
    if submitted and openai_api_key.startswith('sk-'):
        with st.spinner('Calculating...'):
            response = generate_response(txt_input,text)
            result.append(response)
            del openai_api_key

if len(result):
    print(f"result : {result}")
    st.info(response)





system_message = {"role": "system", "content": text}
conversation = []
conversation.append(system_message)
conversation.append({"role": "user", "content": txt_input})

# openai.api_type = "Azure"
# openai.api_base = "https://poc-aitest-skt.openai.azure.com/"
# openai.api_key = "e7dda5bff0324b28bbb5457dd2979c42"
# openai.api_version = "2023-03-15-preview"
# completion = openai.ChatCompletion.create(
#               engine='gpt-35-turbo',
#               messages=conversation,
#               temperature=0.1
#             )


# print(completion['choices'][0]['message']['content'])
# st.info(completion['choices'][0]['message']['content'])

# st.text(completion['choices'][0]['message']['content'])

