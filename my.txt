filename = "embed_result_faiss_" + datetime.now().strftime("%m%d-%H%M") +"-"+ data_path.replace('\\','_')+ embedding_model.replace('/','_')
               

	   with open(filename, "w", encoding='utf8') as file:
            print(f" 질문 : {question}", file=file)
            for i, x in enumerate(document, 1):  # Using enumerate to get the order number starting from 1
                print(f"Page {i}: {len(x.page_content)}", file=file)
                print(x.page_content, file=file)
                print("\n", file=file)



        completion = openai.ChatCompletion.create(
            engine=deployment_name,
            messages=[{"role": "user", "content": f"{prompt}{question}{docs[0:16000]}"}],
            temperature=0.5,
            max_tokens=16000,
            stream=False
        )


def generate_response(txt):
    # Instantiate the LLM model
    llm = OpenAI(temperature=0, openai_api_key=openai_api_key)
    # Split text
    text_splitter = CharacterTextSplitter()
    texts = text_splitter.split_text(txt)
    # Create multiple documents
    docs = [Document(page_content=t) for t in texts]
    # Text summarization
    chain = load_summarize_chain(llm, chain_type='map_reduce')
    return chain.run(docs)
""" OpenAI Make Summary"""
max_context_length = 4096 # 최대 문맥 길이
max_tokens = 1024 # 최대 토큰 길이

# 입력을 여러 번 요청하는 함수
def generate_text(prompt):
    # 요청 문장의 길이가 최대 문맥 길이를 초과하는 경우 나누어 요청
    if len(prompt) > max_context_length:
        prompt_chunks = [prompt[i:i+max_context_length] for i in range(0, len(prompt), max_context_length)]
    else:
        prompt_chunks = [prompt]

    response_texts = []
    openai.api_base =  OPENAI_BASE
    openai.api_type = OPENAI_TYPE
    openai.api_version = OPENAI_VERSION # this may change in the future
    openai.api_key = OPENAI_API_KEY
    for chunk in prompt_chunks:
        # OpenAI API로 요청
        response = openai.Completion.create(
            engine=OPENAI_DEPLOYMENT_SUMMARY,
            prompt=chunk,
            max_tokens=max_tokens,
            temperature=0.9,
            top_p=1,
            stop=None,
            frequency_penalty=0,
            presence_penalty=0.6
        )
        response_text = response.choices[0].text.strip()
        response_texts.append(response_text)

    # 결과를 하나로 합쳐서 반환
    return " ".join(response_texts)

retry_count = 0
summary_result = ''
while retry_count < 3:
    try:
        start_phrase = f'Summariaz to korean the text below in without adding new information.\n\n[Start of text]{openai_text}[End of text]'
        summary_result = generate_text(start_phrase)
        return summary_result
    except Exception as generate_text_error:
        print(f'generate_text Error: {generate_text_error.args}')
        retry_count += 1
        time.sleep(1)
위 요청 방식대로하면 요청을 여러번 나누어서 보내기 때문에 크게 문제가 되지 않지만, 대화형이라 요청 내용이 섞일 수 있는 가능성이 있다.

따라서 두번째 방법, 즉 요청 내용을 최대 크기에 맞게 자르는 방법도 있다.
def generate_split_text(prompt):
    max_context_length = 4096 # 최대 문맥 길이
    if len(prompt) > max_context_length:
        prompt = prompt[:max_context_length]
    openai.api_base =  OPENAI_BASE
    openai.api_type = OPENAI_TYPE
    openai.api_version = OPENAI_VERSION # this may change in the future
    openai.api_key = OPENAI_API_KEY
    response = openai.Completion.create(
        engine=OPENAI_DEPLOYMENT_SUMMARY,
        prompt=prompt,
        max_tokens=1024,
        n=1,
        stop=None,
        temperature=0.5
    )
    
    return response.choices[0].text


model = load_summarize_chain(llm=llm,chain_type=”stuff”)
model.run(document)

from langchain.text_splitter import RecursiveCharacterTextSplitter
char_text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=0) 
docs = char_text_splitter.split_documents(document)

print(len(docs))

model = load_summarize_chain(llm=llm, chain_type=”map_reduce”)
model.run(docs)

model = load_summarize_chain(llm=llm, chain_type=”refine”)
model.run(docs)

system_message = {"role": "system", "content": text}
conversation = []
conversation.append(system_message)
conversation.append({"role": "user", "content": txt_input})

# openai.api_type = "Azure"
# openai.api_base = ""
# openai.api_key = ""
# openai.api_version = "2023-03-15-preview"
# completion = openai.ChatCompletion.create(
#               engine='gpt-35-turbo',
#               messages=conversation,
#               temperature=0.1
#             )


# print(completion['choices'][0]['message']['content'])

https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/chatgpt?pivots=programming-language-chat-completions
