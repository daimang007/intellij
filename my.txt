filename = "embed_result_faiss_" + datetime.now().strftime("%m%d-%H%M") +"-"+ data_path.replace('\\','_')+ embedding_model.replace('/','_')
               

	   with open(filename, "w", encoding='utf8') as file:
            print(f" 질문 : {question}", file=file)
            for i, x in enumerate(document, 1):  # Using enumerate to get the order number starting from 1
                print(f"Page {i}: {len(x.page_content)}", file=file)
                print(x.page_content, file=file)
                print("\n", file=file)



        completion = openai.ChatCompletion.create(
            engine=deployment_name,
            messages=[{"role": "user", "content": f"{prompt}{question}{docs[0:16000]}"}],
            temperature=0.5,
            max_tokens=16000,
            stream=False
        )


def generate_response(txt):
    # Instantiate the LLM model
    llm = OpenAI(temperature=0, openai_api_key=openai_api_key)
    # Split text
    text_splitter = CharacterTextSplitter()
    texts = text_splitter.split_text(txt)
    # Create multiple documents
    docs = [Document(page_content=t) for t in texts]
    # Text summarization
    chain = load_summarize_chain(llm, chain_type='map_reduce')
    return chain.run(docs)
